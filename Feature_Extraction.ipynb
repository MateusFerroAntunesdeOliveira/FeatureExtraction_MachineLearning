{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlqHC8lOsC7X/GASbEN7Np",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MateusFerroAntunesdeOliveira/FeatureExtraction_MachineLearning/blob/main/Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hytWdshl96av"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV4EGJlJ-HAk"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "from skimage import feature\n",
        "from skimage.feature import hog\n",
        "from imutils import paths\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "model = InceptionV3(include_top = False, weights = 'imagenet', pooling = 'avg', input_tensor=Input(shape=(299,299,3)))\n",
        "#model = Xception(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "\n",
        "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= List of paths =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
        "file_list = []\n",
        "# file_list.append(os.listdir(r\"/content/drive/MyDrive/TDE_01/Base/humanos\"))\n",
        "# file_list.append(os.listdir(r\"/content/drive/MyDrive/TDE_01/Base/praia\"))\n",
        "# file_list.append(os.listdir(r\"/content/drive/MyDrive/TDE_01/Base/obras\"))\n",
        "# file_list.append(os.listdir(r\"/content/drive/MyDrive/TDE_01/Base/onibus\"))\n",
        "# file_list.append(os.listdir(r\"/content/drive/MyDrive/TDE_01/Base/dino\"))\n",
        "# file_list.append(os.listdir(r\"/content/drive/MyDrive/TDE_01/Base/elefante\"))\n",
        "# file_list.append(os.listdir(r\"/content/drive/MyDrive/TDE_01/Base/flores\"))\n",
        "# file_list.append(os.listdir(r\"/content/drive/MyDrive/TDE_01/Base/cavalos\"))\n",
        "# file_list.append(os.listdir(r\"/content/drive/MyDrive/TDE_01/Base/montanhas\"))\n",
        "# file_list.append(os.listdir(r\"/content/drive/MyDrive/TDE_01/Base/comida\"))\n",
        "\n",
        "# general path\n",
        "path = '/content/drive/MyDrive/TDE_01/Base/'\n",
        "\n",
        "# list of classes\n",
        "class_names = ['humanos', 'praia', 'obras', 'onibus', 'dino', 'elefante', 'flores', 'cavalos', 'montanhas', 'comida'] \n",
        "\n",
        "\n",
        "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= Feature extraction =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
        "X = []\n",
        "X_deep = []\n",
        "y = []\n",
        "\n",
        "for classes_files, classe in zip (file_list, range(10)):\n",
        "    for i in range(100):\n",
        "      name= str(path) + str(class_names[classe]) + str('/') + str(classes_files[i]) \n",
        "      print(name)\n",
        "      imagem = cv2.imread(name)\n",
        "      # imagem = cv2.resize(imagem,(299,299))  #### <=====\n",
        "\n",
        "      print(imagem.shape)\n",
        "      altura, largura, _ = imagem.shape\n",
        "    \n",
        "      # -------------- Convert the image to RGB and Gray -------------- \n",
        "      cinza = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
        "      rgb   = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      # -------------- Color Histograms -------------- \n",
        "      r_histograma = cv2.calcHist([rgb], [0], None, [256], [0, 256])/(altura*largura)\n",
        "      g_histograma = cv2.calcHist([rgb], [1], None, [256], [0, 256])/(altura*largura)\n",
        "      b_histograma = cv2.calcHist([rgb], [2], None, [256], [0, 256])/(altura*largura)\n",
        "\n",
        "      # -------------- Local Binary Pattern (LBP) -------------- \n",
        "      lbp = feature.local_binary_pattern(cinza, 59, 1, method=\"uniform\")\n",
        "      (lbp_histograma, _) = np.histogram(lbp.ravel(), bins=59, range=(0, 59))\n",
        "      lbp_histograma = lbp_histograma.astype(\"float\")\n",
        "      lbp_histograma /= (lbp_histograma.sum())\n",
        "    \n",
        "      # -------------- Hog (Histogram of Gradient - Direction) -------------- \n",
        "      hg = hog(cinza, orientations=8, pixels_per_cell=(32, 32), cells_per_block=(8, 8), block_norm='L2-Hys')\n",
        "    \n",
        "      # -------------- Concatenate the handcrafted feature sets -------------- \n",
        "      X_image = [lbp_histograma, hg, r_histograma, g_histograma, b_histograma]    \n",
        "      X_image_aux = []\n",
        "      for aux in X_image:\n",
        "          X_image_aux = np.append(X_image_aux, np.ravel(aux))\n",
        "    \n",
        "      X_image = [i for i in X_image_aux]\n",
        "      y.append(classe)\n",
        "      X.append(X_image)\n",
        "      \n",
        "      # -------------- Extract deep features using InceptionV3 pretrained model -------------- \n",
        "      img = cv2.resize(imagem,(299,299))\n",
        "      # img=imagem  ###### <<<=====\n",
        "      xd = image.img_to_array(img)\n",
        "      xd = np.expand_dims(xd, axis=0)\n",
        "      xd = preprocess_input(xd)\n",
        "      deep_features = model.predict(xd)\n",
        "      print(deep_features.shape)\n",
        "      \n",
        "      X_image_aux = []\n",
        "      for aux in deep_features:\n",
        "          X_image_aux = np.append(X_image_aux, np.ravel(aux))\n",
        "    \n",
        "      deep_features = [i for i in X_image_aux]\n",
        "      \n",
        "      X_deep.append(deep_features)\n",
        "            \n",
        "\n",
        "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= Saving the files/folders =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
        "# Saving the extracted features (handcrafted) in a csv file\n",
        "df = pd.DataFrame(X)\n",
        "df.to_csv('X.csv', header=False, index=False)\n",
        "\n",
        "# Saving the extracted features (deep) in a csv file\n",
        "df = pd.DataFrame(X_deep)\n",
        "df.to_csv('X_deep.csv', header = False, index = False)\n",
        "\n",
        "# Saving the classes in a csv file\n",
        "df_class = pd.DataFrame(y)\n",
        "df_class.to_csv('y.csv', header = False, index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np6LtMjB-pzk"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Labels\n",
        "# y = pd.read_csv('/content/drive/MyDrive/TDE_01/Features_Cadu/y.csv', header=None)\n",
        "# y = y.to_numpy()\n",
        "# y = np.ravel(y)\n",
        "# print(y.shape)\n",
        "\n",
        "# handcrafted features\n",
        "# X = pd.read_csv('/content/drive/MyDrive/TDE_01/Features_Cadu/X.csv', header=None)\n",
        "# X = X.to_numpy()\n",
        "# print(X.shape)\n",
        "\n",
        "# deep features\n",
        "# X = pd.read_csv('/content/drive/MyDrive/TDE_01/Features_Cadu/X_deep.csv', header=None)\n",
        "# X = X.to_numpy()\n",
        "# print(X.shape)\n",
        "\n",
        "\n",
        "# ------------ x teste -------------\n",
        "# X = pd.read_csv(\"/content/drive/MyDrive/TDE_01/s1.csv\")\n",
        "# X = X.to_numpy()\n",
        "# print(X.shape)\n",
        "\n",
        "# ------------ y teste -------------\n",
        "# y = pd.read_csv('/content/drive/MyDrive/TDE_01/classes15', header = None)\n",
        "# y = y.to_numpy()\n",
        "# y = np.ravel(y)\n",
        "# print(y.shape)\n",
        "\n",
        "\n",
        "# ---------------------------------------------- PROVA ------------------------------------------------\n",
        "# df = pd.read_csv (r'/content/drive/MyDrive/PROVA_01_ML/leaf.csv', delimiter = ',', header = None)\n",
        "# dataset = df.to_numpy()\n",
        "# X = dataset[:,2:16]\n",
        "# y = dataset[:,0]\n",
        "# print(X.shape)\n",
        "# print(y.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIiJVwr5-x7B"
      },
      "source": [
        "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= FUNÇÃO PRA PLOTAR GRÁFICO BONITIN =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as pl\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.rc('figure', figsize = (11, 11))\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "  plt.imshow(cm, interpolation = 'nearest',cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation = 45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  \n",
        "  if normalize:\n",
        "    cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
        "    print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "    print(\"Confusion matrix, without normalization\")\n",
        "\n",
        "  thresh = cm.max()/2\n",
        "  for i, j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i,j], horizontalalignment=\"center\", color=\"white\" if cm[i,j]>thresh else \"black\")\n",
        "   \n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYxFW31c_r1O"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn import model_selection\n",
        "\n",
        "from warnings import simplefilter\n",
        "simplefilter(action = 'ignore', category = FutureWarning)\n",
        "\n",
        "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= HOLDOUT =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 47, stratify = y)\n",
        "\n",
        "# -------------- DecisionTree --------------\n",
        "# clfa = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 10, min_samples_split = 10)\n",
        "# clfa = clfa.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# -------------- KNN -----------------------\n",
        "# clfa = KNeighborsClassifier(n_neighbors = 1, p = 3, algorithm = 'brute', weights = 'distance')\n",
        "# clfa = clfa.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# ------------ NaiveBayes ------------------\n",
        "# clfa = GaussianNB(var_smoothing = 1e-9)\n",
        "# clfa = clfa.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# ------------ SVM ------------------------- \n",
        "# parameters = [{'C': [0.1, 0.5, 1, 10, 100, 500, 1000], \n",
        "#                'kernel': ['linear']},\n",
        "#               {'C': [0.1, 0.5, 1, 10, 100, 500, 1000], \n",
        "#                'gamma': [0.1, 0.001, 0.0001, 0.00001], \n",
        "#                'kernel': ['rbf']}]\n",
        "\n",
        "# clfa = SVC(probability = True)\n",
        "# clfa = SVC(probability = True, C = 0.1, kernel = 'linear')\n",
        "# clfa = GridSearchCV(clfa, parameters, scoring = 'accuracy', cv = 5)\n",
        "# clfa = clfa.fit(X_train, y_train)\n",
        "# print(clfa.best_params_)\n",
        "\n",
        "\n",
        "# ------------ MLP ------------------------- \n",
        "# clfa = MLPClassifier(hidden_layer_sizes = (16), activation = 'relu', max_iter = 5000,\n",
        "#                      solver = 'lbfgs', tol =  1e-10, early_stopping = True, validation_fraction = 0.2)\n",
        "# clfa = clfa.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# ---------------- PADRÃO PARA TODOS -------------------\n",
        "# predicted = clfa.predict(X_test)\n",
        "# predp = clfa.predict_proba(X_test)\n",
        "# score = clfa.score(X_test, y_test)\n",
        "# matrix = confusion_matrix(y_test, predicted)\n",
        "\n",
        "# print(\"=-\"*20)\n",
        "# print(\"Resultados baseados em HOLDOUT\")\n",
        "# print(\"Taxa de Acerto: %.5f\" % score)\n",
        "\n",
        "# print(\"\\nMatriz de confusão:\")\n",
        "# print(matrix)\n",
        "# print(\"\\n\\n\")\n",
        "\n",
        "# print(\"Matriz de confusão:\")\n",
        "# cm_plot_labels = ['1','2','3','4','5','6','7','8','9', '10', '11', '12', '13', '14', '15', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36']\n",
        "# plot_confusion_matrix(cm,cm_plot_labels,title ='Confusion Matrix')\n",
        "# print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= VALIDAÇÃO CRUZADA =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
        "\n",
        "# -------------- DecisionTree --------------\n",
        "# clfb = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 10, min_samples_split = 10)\n",
        "# folds = 5\n",
        "\n",
        "\n",
        "# -------------- KNN -----------------------\n",
        "# clfb = KNeighborsClassifier(n_neighbors = 6, p = 1, algorithm = 'kd_tree', weights = 'distance')\n",
        "# folds = 5\n",
        "\n",
        "\n",
        "# ------------ NaiveBayes ------------------\n",
        "# clfb = GaussianNB(var_smoothing = 1e-12)\n",
        "# folds = 5\n",
        "\n",
        "\n",
        "# ------------ SVM ------------------------- \n",
        "# clfb = SVC(probability = True)\n",
        "# clfb = SVC(probability = True, C = 250, kernel = 'linear')\n",
        "# folds = 5\n",
        "# clfb = GridSearchCV(clfb, parameters, scoring = 'accuracy', cv = folds)\n",
        "\n",
        "\n",
        "# ------------ MLP ------------------------- \n",
        "# clfb = MLPClassifier(hidden_layer_sizes = (16), activation = 'relu', max_iter = 5000, \n",
        "#                      solver = 'sgd', tol = 1e-10, early_stopping = True, validation_fraction = 0.2)\n",
        "# folds = 10\n",
        "\n",
        "\n",
        "# ---------------- PADRÃO PARA TODOS -------------------\n",
        "# result = model_selection.cross_val_score(clfb, X, y, cv = folds)\n",
        "# Z = model_selection.cross_val_predict(clfb, X, y, cv = folds)\n",
        "# cm = confusion_matrix(y, Z)\n",
        "# f1Score = f1_score(y, Z, pos_label = 0, average = 'binary')\n",
        "\n",
        "# print(\"=-\"*20)\n",
        "# print(\"Resultados baseados em Validacao Cruzada\")\n",
        "# print(\"Quantidade de folds: %d\" % folds)\n",
        "# print(\"Taxa de Acerto: %.5f\" % result.mean())\n",
        "# print(\"Desvio padrao: %.5f\" % result.std())\n",
        "# print(\"F1_score: %.5f\" % f1Score)\n",
        "# print(\"=-\"*20)\n",
        "\n",
        "# print(\"\\nMatriz de confusão:\")\n",
        "# print(cm)\n",
        "\n",
        "# soma = 0\n",
        "# main = 0\n",
        "\n",
        "# for i in range(len(cm)):\n",
        "#   for j in range(len(cm[i])):\n",
        "#     soma += cm[i][j]\n",
        "#     if i == j:\n",
        "#       main += cm[i][j]\n",
        "\n",
        "# print(\"Soma de todos os valores: \", soma)\n",
        "# print(\"Soma dos valores das colunas principais: \", main)\n",
        "\n",
        "# print(\"Matriz de confusão:\")\n",
        "# cm_plot_labels = ['1','2','3','4','5','6','7','8','9', '10', '11', '12', '13', '14', '15', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36']\n",
        "# plot_confusion_matrix(cm, cm_plot_labels, title = 'Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kA0yqWq_1Uj"
      },
      "source": [
        "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= Plot mistakes (images) =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
        "print(predicted.shape)\n",
        "for i in range(len(predicted)):\n",
        "    if (predicted[i] != y_test[i]):\n",
        "        print(i)\n",
        "        print(\"predicted[i]:\", predicted[i], class_names[predicted[i]])\n",
        "        print(\"y_test[i]:\", y_test[i], class_names[y_test[i]])\n",
        "        dist=1\n",
        "        j=0\n",
        "        while (j<len(X) and dist !=0): \n",
        "            dist = np.linalg.norm(X[j]-X_test[i])\n",
        "            j+=1\n",
        "        print(\"Label:\", y[j-1], class_names[y[j-1]], \"  /  Prediction: \", predicted[i], class_names[predicted[i]], predp[i][predicted[i]])\n",
        "        name = \"/content/drive/MyDrive/TDE_01/Base/\"+ str(class_names[y[j-1]]) + \"/\" + str(j)+ \".jpg\" \n",
        "        print(name)\n",
        "        im=cv2.imread(name)\n",
        "        cv2_imshow(im)\n",
        "        print(\"=============================================================================\")\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}